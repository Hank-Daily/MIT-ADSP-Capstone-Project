{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alivWB24K_5S"
   },
   "source": [
    "# **Music Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #Used to ignore the warning given as output of the code.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # Basic libraries of python for numeric and dataframe computations.\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt #Basic library for data visualization.\n",
    "import seaborn as sns #Slightly advanced library for data visualization\n",
    "\n",
    "# from sklearn.metrics.pairwise import cosine_similarity #To compute the cosine similarity between two vectors.\n",
    "from collections import defaultdict #A dictionary output that does not raise a key error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # A performance metrics in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll2E42N1K_5d"
   },
   "source": [
    "# **Milestone 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWO4C8KsK_5e"
   },
   "source": [
    "Now that we have explored the data, let's apply different algorithms to build recommendation systems\n",
    "\n",
    "**Note:** Use the shorter version of the data i.e. the data after the cutoffs as used in Milestone 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('C:/MITADSC/Capstone/df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Distillation</td>\n",
       "      <td>Erin McKeown</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine</td>\n",
       "      <td>Sawdust</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man</td>\n",
       "      <td>You Know I'm No Good</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  song_id  play_count                            title  \\\n",
       "0     6958      447           1               Daisy And Prudence   \n",
       "1     6958      512           1  The Ballad of Michael Valentine   \n",
       "2     6958      549           1        I Stand Corrected (Album)   \n",
       "3     6958      703           1            They Might Follow You   \n",
       "4     6958      719           1                       Monkey Man   \n",
       "\n",
       "                release      artist_name  year  \n",
       "0          Distillation     Erin McKeown  2000  \n",
       "1               Sawdust      The Killers  2004  \n",
       "2       Vampire Weekend  Vampire Weekend  2007  \n",
       "3           Tiny Vipers      Tiny Vipers  2007  \n",
       "4  You Know I'm No Good    Amy Winehouse  2007  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.drop('Unnamed: 0', 1, inplace=True) \n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ituk9wA4Idib"
   },
   "source": [
    "### **Popularity-Based Recommendation Systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "462hsbxaI1ED"
   },
   "source": [
    "Let's take the count and sum of play counts of the songs and build the popularity recommendation systems on the basis of the sum of play counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UXhBZlDE-jEu"
   },
   "outputs": [],
   "source": [
    "#Calculating average play_count\n",
    "average_count = df_final.groupby('song_id').mean()['play_count'] #Hint: Use groupby function on the song_id column. \n",
    "\n",
    "#Calculating the frequency a song is played.\n",
    "play_freq = df_final.groupby('song_id').sum()['play_count']#Hint: Use groupby function on the song_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v2XYdXvWdyys"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_count</th>\n",
       "      <th>play_freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.631387</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.464286</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.616822</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.715232</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.727273</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_count  play_freq\n",
       "song_id                      \n",
       "21        1.631387        447\n",
       "22        1.464286        205\n",
       "50        1.616822        173\n",
       "52        1.715232        777\n",
       "62        1.727273        209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a dataframe with the average_count and play_freq\n",
    "final_play = pd.DataFrame({'avg_count':average_count, 'play_freq':play_freq})\n",
    "final_play.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dq_Ue0spK_5g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnCT-A7RK_5g"
   },
   "source": [
    "Now, let's create a function to find the top n songs for a recommendation based on the average play count of song. We can also add a threshold for a minimum number of playcounts for a song to be considered for recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QiT9FV3GNCrb"
   },
   "outputs": [],
   "source": [
    "#Build the function for finding top n songs\n",
    "\n",
    "def top_n_songs(average_count, n, play_freq):\n",
    "    \n",
    "    #Finding products with minimum number of interactions\n",
    "    recommendations = final_play[final_play['play_freq'] > play_freq]\n",
    "    \n",
    "    #Sorting values w.r.t average rating \n",
    "    recommendations = recommendations.sort_values(by = 'avg_count', ascending = False)\n",
    "    \n",
    "    return recommendations.index[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GpZt_BeXgz4F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7224, 6450, 8324, 9942, 8483, 5531, 657, 5653, 614, 2220]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recommend top 10 songs using the function defined above with at least 100 plays\n",
    "top_songs = list(top_n_songs(final_play, 10, 100))\n",
    "top_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf13HrPPJeWT"
   },
   "source": [
    "### **User User Similarity-Based Collaborative Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROcEpduohdua"
   },
   "source": [
    "To build the user-user-similarity based and subsequent models we will use the \"surprise\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aKLrKn8IfGjk"
   },
   "outputs": [],
   "source": [
    "#Install the surprise package using pip. Uncomment and run the below code to do the same. \n",
    "#!pip install surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UJ1wEylUpexj"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# class is used to parse a file containing play_counts, data should be in structure - user; item ; play_count\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# for tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# for splitting the data in train and test dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# for implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# for implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing KFold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "#For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBW4BUhWTsnm"
   },
   "source": [
    "### Some useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhFa_4aHHchr"
   },
   "source": [
    "The below is the function to calculate precision@k and recall@k, RMSE and F1_Score@k to evaluate the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOvOgjGWrMVV"
   },
   "source": [
    "**Think About It:** Which metric should be used for this problem to compare different models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Rxn-GahOTsnm"
   },
   "outputs": [],
   "source": [
    "#The function to calulate the RMSE, precision@k, recall@k and F_1 score. \n",
    "def precision_recall_at_k(model, k=30, threshold=1.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    #Making predictions on the test data\n",
    "    predictions=model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    #Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)),3)\n",
    "    #Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)),3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    print('Precision: ', precision) #Command to print the overall precision\n",
    "    print('Recall: ', recall) #Command to print the overall recall\n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall),3)) # Formula to compute the F-1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcmLRxH4IjfG"
   },
   "source": [
    "**Think About It:** In the function precision_recall_at_k above the threshold value used is 1.5. How precision and recall are affected by chaning the threshold? What is the intuition behind using the threshold value 1.5? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [],
   "source": [
    "# Instantiating Reader scale with expected play count\n",
    "reader = Reader(rating_scale=(0, 5)) #use (0,5)\n",
    "\n",
    "# loading the dataset\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'song_id', 'play_count']], reader) #Take only \"user_id\",\"song_id\", and \"play_count\"\n",
    "\n",
    "# splitting the data into train and test dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.4, random_state=42) # Take test_size=0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuTmLjUP1aED"
   },
   "source": [
    "**Think About It:** How changing the test size would change the results and outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vO3FL7iape8A",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0817\n",
      "Precision:  0.401\n",
      "Recall:  0.705\n",
      "F_1 score:  0.511\n"
     ]
    }
   ],
   "source": [
    "#Build the default user-user-similarity model\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True}\n",
    "\n",
    "#KNN algorithm is used to find desired similar items.\n",
    "sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1) #use random_state=1 \n",
    "\n",
    "# Train the algorithm on the trainset, and predict play_count for the testset\n",
    "sim_user_user.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k =30.\n",
    "precision_recall_at_k(sim_user_user, k=30) #Use sim_user_user model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzcdlWmer6GA"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Sxd23bZ9pe_x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=2, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play_count for a sample user with a listened song.\n",
    "sim_user_user.predict(\"6958\", \"1671\", r_ui=2, verbose=True) #use user id 6958 and song_id 1671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PbFcBj1PpfEV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='3232', r_ui=None, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play_count for a sample user with a song not-listened by the user.\n",
    "sim_user_user.predict(\"6958\",\"3232\", verbose=True) #Use user_id 6958 and song_id 3232"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9EVM7DysC47"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt1QBiylsIOm"
   },
   "source": [
    "Now, let's try to tune the model and see if we can improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T3diJPL7-tVw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0038432128090233\n",
      "{'k': 30, 'min_k': 9, 'sim_options': {'name': 'pearson_baseline', 'user_based': True, 'min_support': 2}}\n"
     ]
    }
   ],
   "source": [
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\",'pearson',\"pearson_baseline\"],\n",
    "                              'user_based': [True], \"min_support\":[2,4]}\n",
    "              }\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data) #Use entire data for GridSearch\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PujRJA8X_JEJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0873\n",
      "Precision:  0.4\n",
      "Recall:  0.696\n",
      "F_1 score:  0.508\n"
     ]
    }
   ],
   "source": [
    "# Train the best model found in above gridsearch.\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True}\n",
    "\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_user_user_optimized = KNNBasic(sim_options=sim_options, k=30, min_k=9, random_state=1, verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "sim_user_user_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k also with k =10.\n",
    "precision_recall_at_k(sim_user_user_optimized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH5OBZ7Nse6m"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FgV63lHiq1TV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=2, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play count for a user who has listened to the song. Take user_id 6958, song_id 1671 and r_ui=2\n",
    "sim_user_user_optimized.predict(\"6958\", \"1671\", r_ui = 2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HXO2Ztjhq1bN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='3232', r_ui=None, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play count for a song that is not listened by the user (with user_id 6958)\n",
    "sim_user_user_optimized.predict(\"6958\", \"3232\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdpJ--8QWuzz"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ9M4pplNbWS"
   },
   "source": [
    "**Think About It:** Along with making predictions on listened and unknown songs can we get 5 nearest neighbors (most similar) to a certain user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TbFle7cKmBJG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 8, 9, 11]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use inner id 0. \n",
    "sim_user_user_optimized.get_neighbors(0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are - \n",
    "\n",
    "- data: a **song** dataset\n",
    "- user_id: a user id **against which we want the recommendations**\n",
    "- top_n: the **number of songs we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the play_count**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index='user_id', columns='song_id', values='play_count')\n",
    "    \n",
    "    # extracting those song ids which the user_id has not interacted yet\n",
    "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # looping through each of the product ids which user_id has not interacted yet\n",
    "    for item_id in non_interacted_products:\n",
    "        \n",
    "        # predicting the ratings for those non interacted product ids by this user\n",
    "        est = algo.predict(user_id, item_id).est\n",
    "        \n",
    "        # appending the predicted ratings\n",
    "        recommendations.append((item_id, est))\n",
    "\n",
    "    # sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return recommendations[:top_n] # returing top n highest predicted rating products for this user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_8944/2304360897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Make top 5 recommendations for user_id 6958 with a similarity-based recommendation engine.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecommendations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"6958\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_user_user_optimized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_8944/1652913846.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# creating an user item interactions matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'song_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'play_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# extracting those song ids which the user_id has not interacted yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   7791\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7793\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(data, index, columns, values)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   4079\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4081\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4083\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         unstacker = _Unstacker(\n\u001b[0m\u001b[0;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "#Make top 5 recommendations for user_id 6958 with a similarity-based recommendation engine.\n",
    "recommendations = get_recommendations(df_final, \"6958\", 5, sim_user_user_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5WfIX0Z6_q2"
   },
   "outputs": [],
   "source": [
    "#Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns=['song_id', 'predicted_ratings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyhThMOttWjj"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghwEJY2e7INB"
   },
   "source": [
    "### Correcting the play_counts and Ranking the above songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39Hs7ZbO9v3O"
   },
   "outputs": [],
   "source": [
    "def ranking_songs(recommendations, final_rating):\n",
    "  # sort the songs based on play counts\n",
    "  ranked_songs = final_rating.loc[[items[0] for items in recommendations]].sort_values('play_freq', ascending=False)[['play_freq']].reset_index()\n",
    "\n",
    "  # merge with the recommended songs to get predicted play_count\n",
    "  ranked_songs = ranked_songs.merge(pd.DataFrame(recommendations, columns=['song_id', 'predicted_ratings']), on='song_id', how='inner')\n",
    "\n",
    "  # rank the songs based on corrected play_counts\n",
    "  ranked_songs['corrected_ratings'] = ranked_songs['predicted_ratings'] - 1 / np.sqrt(ranked_songs['play_freq'])\n",
    "\n",
    "  # sort the songs based on corrected play_counts\n",
    "  ranked_songs = ranked_songs.sort_values('corrected_ratings', ascending=False)\n",
    "  \n",
    "  return ranked_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQvst41lOoMX"
   },
   "source": [
    "**Think About It:** In the above function to make the correction in the predicted play_count a quantity 1/np.sqrt(n) is subtracted. What is the intuition behind it? Is it also possible to add this quantity instead of subtracting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoiAL_vH8miC"
   },
   "outputs": [],
   "source": [
    "#Applying the ranking_songs function on the final_play data. \n",
    "ranking_products(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOwwGsH8toLG"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbzJKk7Tsnr"
   },
   "source": [
    "### Item Item Similarity-based collaborative filtering recommendation systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "W5RMcdzjTsns",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0320\n",
      "Precision:  0.316\n",
      "Recall:  0.572\n",
      "F_1 score:  0.407\n"
     ]
    }
   ],
   "source": [
    "#Apply the item-item similarity collaborative filtering model with random_state=1 and evaluate the model performance.\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False}\n",
    "\n",
    "#KNN algorithm is used to find desired similar items.\n",
    "sim_item_item = KNNBasic(sim_options=sim_options, random_state=1, verbose=False)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "sim_item_item.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k =10.\n",
    "precision_recall_at_k(sim_item_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfdIJ6XWunx0"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "5yILOxXRTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 5.00   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=5, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play count for a sample user_id 6958 and song (with song_id 1671) heard by the user.\n",
    "sim_item_item.predict(\"6958\", \"1671\", r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "jSn8oK3JZsTc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 5.00   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=5, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play count for a user that has not listened to the song (with song_id 1671)\n",
    "df_final.loc[df.final['column_name'] == some_value]\n",
    "sim_item_item.predict(\"6958\", \"1671\", r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxE9fJ8Dupby"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "f5bcZ3HgTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884260193514258\n",
      "{'k': 20, 'min_k': 6, 'sim_options': {'name': 'pearson_baseline', 'user_based': False, 'min_support': 2}}\n"
     ]
    }
   ],
   "source": [
    "#Apply grid search for enhancing model performance\n",
    "\n",
    "# setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {'k': [10, 20, 30], 'min_k': [3, 6, 9],\n",
    "              'sim_options': {'name': [\"cosine\",'pearson',\"pearson_baseline\"],\n",
    "                              'user_based': [False], \"min_support\":[2,4]}\n",
    "              }\n",
    "\n",
    "# performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# find best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# Extract the combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXLxjLEQYvWk"
   },
   "source": [
    "**Think About It:** How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the list of hyperparameter [here](https://surprise.readthedocs.io/en/stable/knn_inspired.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "dSeiM1qeTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0248\n",
      "Precision:  0.371\n",
      "Recall:  0.562\n",
      "F_1 score:  0.447\n"
     ]
    }
   ],
   "source": [
    "#Apply the best modle found in the grid search.\n",
    "sim_options =  {'name': 'msd',\n",
    "               'user_based': False}\n",
    "\n",
    "# creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_item_item_optimized = KNNBasic(sim_options=sim_options, k=20, min_k=6 , random_state=1, verbose=False)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "sim_item_item_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k, f1_score@k and RMSE\n",
    "precision_recall_at_k(sim_item_item_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxXelRIluvfh"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "gIBRRvdoTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=None, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the play_count by a user(user_id 6958) for the song (song_id 1671)\n",
    "sim_item_item_optimized.predict(\"6958\", \"1671\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "LNEgcI9PTsnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.70   {'was_impossible': True, 'reason': 'User and/or item is unknown.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='3232', r_ui=None, est=1.698939503494818, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting play count for a sample user_id 6958 with song_id 3232 which is not heard by the user.\n",
    "sim_item_item_optimized.predict(\"6958\", \"3232\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf3kDSepuwcw"
   },
   "source": [
    "**Observations and Insights:______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "ZRJS4oDFTsnu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 16, 18, 29, 39]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find five most similar users to the user with inner id 0\n",
    "sim_item_item_optimized.get_neighbors(0, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "rzoEbuZFTsnu"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_3248/4144517792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Making top 5 recommendations for user_id 6958 with item_item_similarity-based recommendation engine.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecommendations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"6958\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_item_item_optimized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_3248/1652913846.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# creating an user item interactions matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'song_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'play_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# extracting those song ids which the user_id has not interacted yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   7791\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7793\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(data, index, columns, values)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   4079\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4081\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4083\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         unstacker = _Unstacker(\n\u001b[0m\u001b[0;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "#Making top 5 recommendations for user_id 6958 with item_item_similarity-based recommendation engine.\n",
    "recommendations = get_recommendations(df_final, \"6958\", 5, sim_item_item_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kXVTiysTsnv"
   },
   "outputs": [],
   "source": [
    "#Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
    "pd.DataFrame(recommendations, columns=['song_id', 'predicted_play_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gewfmTATsnv"
   },
   "outputs": [],
   "source": [
    "#Applying the ranking_songs function. \n",
    "ranking_products(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ore9XTFgv5Np"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "### Model Based Collaborative Filtering - Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJynidJCw-ti"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "07-2PT5Ssjqm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0026\n",
      "Precision:  0.432\n",
      "Recall:  0.654\n",
      "F_1 score:  0.52\n"
     ]
    }
   ],
   "source": [
    "# Build baseline model using svd\n",
    "svd = SVD(random_state=1)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score@k, and RMSE\n",
    "precision_recall_at_k(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "yWIhfdxXsjqm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 2.00   est = 1.70   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=2, est=1.698939503494818, details={'was_impossible': False})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making prediction for user (with user_id 6958) to song (with song_id 1671), take r_ui=2\n",
    "svd.predict(\"6958\", \"1671\", r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APm-uMSvcAMf"
   },
   "outputs": [],
   "source": [
    "# Making prediction for user who has not listened the song (song_id 3232)\n",
    "svd.predict(\"6958\", \"3232\", r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23tnRUJJxWTR"
   },
   "source": [
    "#### Improving matrix factorization based recommendation system by tuning its hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "4bM81V_hvtwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0030215721308338\n",
      "{'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# set the parameter space to tune\n",
    "param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.001, 0.005, 0.01],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}\n",
    "\n",
    "# performing 3-fold gridsearch cross validation\n",
    "gs_ = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting data\n",
    "gs_.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs_.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSgBRcL1xnVC"
   },
   "source": [
    "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "TA_7xe-nnhuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0085\n",
      "Precision:  0.414\n",
      "Recall:  0.645\n",
      "F_1 score:  0.504\n"
     ]
    }
   ],
   "source": [
    "# Building the optimized SVD model using optimal hyperparameters\n",
    "svd_optimized = SVD(n_epochs = 30, lr_all = 0.01, reg_all = 0.2, random_state=1)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "svd_optimized = svd_optimized.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score@k, and RMSE\n",
    "precision_recall_at_k(svd_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3t5JdBmxz8l"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "s6C1PAfboM8_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 5.00   est = 1.70   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='1671', r_ui=5, est=1.698939503494818, details={'was_impossible': False})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using svd_algo_optimized model to recommend for userId 6958 and song_id 1671.\n",
    "svd_optimized.predict(\"6958\", \"1671\", r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "k1xjn3kOoQyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = None   est = 1.70   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='6958', iid='3232', r_ui=None, est=1.698939503494818, details={'was_impossible': False})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using svd_algo_optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating.\n",
    "svd_optimized.predict(\"6958\", \"3232\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm732Wuvy76R"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "1LGeE2EB_n90"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_3248/2315092080.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecommendations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"6958\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvd_optimized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_3248/1652913846.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(data, user_id, top_n, algo)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# creating an user item interactions matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0muser_item_interactions_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'song_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'play_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# extracting those song ids which the user_id has not interacted yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   7791\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7793\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7795\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(data, index, columns, values)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   4079\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4081\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4083\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_1d_only_ea_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_unstack_extension_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         unstacker = _Unstacker(\n\u001b[0m\u001b[0;32m    461\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index contains duplicate entries, cannot reshape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "# Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm.\n",
    "recommendations = get_recommendations(df_final, \"6958\", 5, svd_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "6ngiGSJU818M"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ranking_products' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_3248/2131376159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Ranking songs based on above recommendations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mranking_products\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommendations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_play\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ranking_products' is not defined"
     ]
    }
   ],
   "source": [
    "#Ranking songs based on above recommendations\n",
    "ranking_products(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SepUU1Efy_9Z"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57b31de5"
   },
   "source": [
    "### Cluster Based Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Xv2AZCszCdN"
   },
   "source": [
    "In **clustering-based recommendation systems**, we explore the **similarities and differences** in people's tastes in songs based on how they rate different songs. We cluster similar users together and recommend songs to a user based on play_counts from other users in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "0c4b20e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0428\n",
      "Precision:  0.408\n",
      "Recall:  0.493\n",
      "F_1 score:  0.446\n"
     ]
    }
   ],
   "source": [
    "# Make baseline clustering model\n",
    "clust_baseline = CoClustering(random_state=1)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "clust_baseline.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k with k =10.\n",
    "precision_recall_at_k(clust_baseline, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "11dbdc0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 1671       r_ui = 5.00   est = 1.36   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=1671, r_ui=5, est=1.3627795906030837, details={'was_impossible': False})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making prediction for user_id 6958 and song_id 1671.\n",
    "clust_baseline.predict(6958, 1671, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "dab1aaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 6958       item: 3232       r_ui = 5.00   est = 1.55   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=6958, iid=3232, r_ui=5, est=1.5488944215348255, details={'was_impossible': False})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making prediction for user (userid 6958) for a song(song_id 3232) not heard by the user.\n",
    "clust_baseline.predict(6958, 3232, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2fd66f5"
   },
   "source": [
    "#### Improving clustering-based recommendation system by tuning its hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "efe7d8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0484356801913162\n",
      "{'n_cltr_u': 5, 'n_cltr_i': 5, 'n_epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "# set the parameter space to tune\n",
    "param_grid = {'n_cltr_u':[5,6,7,8], 'n_cltr_i': [5,6,7,8], 'n_epochs': [10,20,30]}\n",
    "\n",
    "# performing 3-fold gridsearch cross validation\n",
    "gs = GridSearchCV(CoClustering, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# fitting data\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CS6aMVJLyj21"
   },
   "source": [
    "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/co_clustering.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a7a8a30"
   },
   "outputs": [],
   "source": [
    "# Train the tuned Coclustering algorithm\n",
    "clust_tuned = CoClustering(n_cltr_u=3,n_cltr_i=3, n_epochs=40, random_state=1)\n",
    "\n",
    "# training the algorithm on the trainset\n",
    "clust_tuned.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k with k =10.\n",
    "precision_recall_at_k(clust_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-Jvce1gznKa"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ba5b26b"
   },
   "outputs": [],
   "source": [
    "#Using co_clustering_optimized model to recommend for userId 6958 and song_id 1671.\n",
    "clust_tuned.predict(6958, 1671, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec582940"
   },
   "outputs": [],
   "source": [
    "#Use Co_clustering based optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating.\n",
    "clust_tuned.predict(6958, 3232, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjGUSMqrzoDH"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df9e28ba"
   },
   "source": [
    "#### Implementing the recommendation algorithm based on optimized CoClustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0f36e15"
   },
   "outputs": [],
   "source": [
    "#Getting top 5 recommendations for user_id 6958 using \"Co-clustering based optimized\" algorithm.\n",
    "clustering_recommendations = get_recommendations(df_final, \"6958\", 5, clust_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1696941"
   },
   "source": [
    "### Correcting the play_count and Ranking the above songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c186f13b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ranking songs based on above recommendations\n",
    "ranking_products(recommendations, final_play)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uJ_nZjBzvKH"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U56oSNsR-F2"
   },
   "source": [
    "### Content Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aTEqaOjhoEg"
   },
   "source": [
    "**Think About It:** So far we have only used the play_count of songs to find recommendations but we have other information/features on songs as well. Can we take those song features into account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RhUx2jgp4frC"
   },
   "outputs": [],
   "source": [
    "df_small=df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UX826CsjR-F3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Distillation</td>\n",
       "      <td>Erin McKeown</td>\n",
       "      <td>2000</td>\n",
       "      <td>Daisy And Prudence Distillation Erin McKeown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine</td>\n",
       "      <td>Sawdust</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Ballad of Michael Valentine Sawdust The Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>Vampire Weekend</td>\n",
       "      <td>2007</td>\n",
       "      <td>I Stand Corrected (Album) Vampire Weekend Vamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>Tiny Vipers</td>\n",
       "      <td>2007</td>\n",
       "      <td>They Might Follow You Tiny Vipers Tiny Vipers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man</td>\n",
       "      <td>You Know I'm No Good</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>2007</td>\n",
       "      <td>Monkey Man You Know I'm No Good Amy Winehouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  song_id  play_count                            title  \\\n",
       "0     6958      447           1               Daisy And Prudence   \n",
       "1     6958      512           1  The Ballad of Michael Valentine   \n",
       "2     6958      549           1        I Stand Corrected (Album)   \n",
       "3     6958      703           1            They Might Follow You   \n",
       "4     6958      719           1                       Monkey Man   \n",
       "\n",
       "                release      artist_name  year  \\\n",
       "0          Distillation     Erin McKeown  2000   \n",
       "1               Sawdust      The Killers  2004   \n",
       "2       Vampire Weekend  Vampire Weekend  2007   \n",
       "3           Tiny Vipers      Tiny Vipers  2007   \n",
       "4  You Know I'm No Good    Amy Winehouse  2007   \n",
       "\n",
       "                                                text  \n",
       "0       Daisy And Prudence Distillation Erin McKeown  \n",
       "1  The Ballad of Michael Valentine Sawdust The Ki...  \n",
       "2  I Stand Corrected (Album) Vampire Weekend Vamp...  \n",
       "3      They Might Follow You Tiny Vipers Tiny Vipers  \n",
       "4      Monkey Man You Know I'm No Good Amy Winehouse  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the \"title\",\"release\",\"artist_name\" columns to create a different column named \"text\"\n",
    "df_small['text']=df_small['title'].astype(str)+' '+df_small['release']+' '+df_small['artist_name']\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WdXw4U-wR-F4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Daisy And Prudence Distillation Erin McKeown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine</td>\n",
       "      <td>The Ballad of Michael Valentine Sawdust The Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)</td>\n",
       "      <td>I Stand Corrected (Album) Vampire Weekend Vamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You</td>\n",
       "      <td>They Might Follow You Tiny Vipers Tiny Vipers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man</td>\n",
       "      <td>Monkey Man You Know I'm No Good Amy Winehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>40245</td>\n",
       "      <td>2161</td>\n",
       "      <td>1</td>\n",
       "      <td>The Last Song</td>\n",
       "      <td>The Last Song The All-American Rejects The All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>33280</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>Invincible</td>\n",
       "      <td>Invincible Black Holes And Revelations Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>33280</td>\n",
       "      <td>1536</td>\n",
       "      <td>2</td>\n",
       "      <td>Paper Gangsta</td>\n",
       "      <td>Paper Gangsta The Fame Monster Lady GaGa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>1246</td>\n",
       "      <td>3466</td>\n",
       "      <td>1</td>\n",
       "      <td>Starlight</td>\n",
       "      <td>Starlight Starlight Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>40989</td>\n",
       "      <td>7388</td>\n",
       "      <td>1</td>\n",
       "      <td>Tangerine  (Album Version)</td>\n",
       "      <td>Tangerine  (Album Version) The Complete Led Ze...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  song_id  play_count                            title  \\\n",
       "0        6958      447           1               Daisy And Prudence   \n",
       "1        6958      512           1  The Ballad of Michael Valentine   \n",
       "2        6958      549           1        I Stand Corrected (Album)   \n",
       "3        6958      703           1            They Might Follow You   \n",
       "4        6958      719           1                       Monkey Man   \n",
       "...       ...      ...         ...                              ...   \n",
       "4941    40245     2161           1                    The Last Song   \n",
       "5000    33280      519           1                       Invincible   \n",
       "5010    33280     1536           2                    Paper Gangsta   \n",
       "5698     1246     3466           1                        Starlight   \n",
       "7641    40989     7388           1       Tangerine  (Album Version)   \n",
       "\n",
       "                                                   text  \n",
       "0          Daisy And Prudence Distillation Erin McKeown  \n",
       "1     The Ballad of Michael Valentine Sawdust The Ki...  \n",
       "2     I Stand Corrected (Album) Vampire Weekend Vamp...  \n",
       "3         They Might Follow You Tiny Vipers Tiny Vipers  \n",
       "4         Monkey Man You Know I'm No Good Amy Winehouse  \n",
       "...                                                 ...  \n",
       "4941  The Last Song The All-American Rejects The All...  \n",
       "5000        Invincible Black Holes And Revelations Muse  \n",
       "5010           Paper Gangsta The Fame Monster Lady GaGa  \n",
       "5698                           Starlight Starlight Muse  \n",
       "7641  Tangerine  (Album Version) The Complete Led Ze...  \n",
       "\n",
       "[629 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the columns 'user_id', 'song_id', 'play_count', 'title', 'text' from df_small data\n",
    "col_names = ['user_id', 'song_id', 'play_count', 'title', 'text']\n",
    "df_small = df_small[col_names]\n",
    "\n",
    "#drop the duplicates from the title column\n",
    "df_small.drop_duplicates(subset = ['title'], keep = 'first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Daisy And Prudence</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence Distillation Erin McKeown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Ballad of Michael Valentine</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine Sawdust The Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I Stand Corrected (Album)</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album) Vampire Weekend Vamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>They Might Follow You</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You Tiny Vipers Tiny Vipers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monkey Man</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man You Know I'm No Good Amy Winehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Half Of My Heart</th>\n",
       "      <td>47786</td>\n",
       "      <td>9139</td>\n",
       "      <td>1</td>\n",
       "      <td>Half Of My Heart Battle Studies John Mayer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bitter Sweet Symphony</th>\n",
       "      <td>47786</td>\n",
       "      <td>9186</td>\n",
       "      <td>1</td>\n",
       "      <td>Bitter Sweet Symphony Bitter Sweet Symphony Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Police And The Private</th>\n",
       "      <td>47786</td>\n",
       "      <td>9351</td>\n",
       "      <td>2</td>\n",
       "      <td>The Police And The Private Live It Out Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Just Friends</th>\n",
       "      <td>47786</td>\n",
       "      <td>9543</td>\n",
       "      <td>1</td>\n",
       "      <td>Just Friends Back To Black Amy Winehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He Can Only Hold Her</th>\n",
       "      <td>47786</td>\n",
       "      <td>9847</td>\n",
       "      <td>1</td>\n",
       "      <td>He Can Only Hold Her Back To Black Amy Winehouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138301 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id  song_id  play_count  \\\n",
       "title                                                           \n",
       "Daisy And Prudence                  6958      447           1   \n",
       "The Ballad of Michael Valentine     6958      512           1   \n",
       "I Stand Corrected (Album)           6958      549           1   \n",
       "They Might Follow You               6958      703           1   \n",
       "Monkey Man                          6958      719           1   \n",
       "...                                  ...      ...         ...   \n",
       "Half Of My Heart                   47786     9139           1   \n",
       "Bitter Sweet Symphony              47786     9186           1   \n",
       "The Police And The Private         47786     9351           2   \n",
       "Just Friends                       47786     9543           1   \n",
       "He Can Only Hold Her               47786     9847           1   \n",
       "\n",
       "                                                                              text  \n",
       "title                                                                               \n",
       "Daisy And Prudence                    Daisy And Prudence Distillation Erin McKeown  \n",
       "The Ballad of Michael Valentine  The Ballad of Michael Valentine Sawdust The Ki...  \n",
       "I Stand Corrected (Album)        I Stand Corrected (Album) Vampire Weekend Vamp...  \n",
       "They Might Follow You                They Might Follow You Tiny Vipers Tiny Vipers  \n",
       "Monkey Man                           Monkey Man You Know I'm No Good Amy Winehouse  \n",
       "...                                                                            ...  \n",
       "Half Of My Heart                        Half Of My Heart Battle Studies John Mayer  \n",
       "Bitter Sweet Symphony            Bitter Sweet Symphony Bitter Sweet Symphony Th...  \n",
       "The Police And The Private           The Police And The Private Live It Out Metric  \n",
       "Just Friends                              Just Friends Back To Black Amy Winehouse  \n",
       "He Can Only Hold Her              He Can Only Hold Her Back To Black Amy Winehouse  \n",
       "\n",
       "[138301 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the title column as the index\n",
    "df_small.set_index('title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6958</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>Daisy And Prudence</td>\n",
       "      <td>Daisy And Prudence Distillation Erin McKeown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6958</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>The Ballad of Michael Valentine</td>\n",
       "      <td>The Ballad of Michael Valentine Sawdust The Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6958</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>I Stand Corrected (Album)</td>\n",
       "      <td>I Stand Corrected (Album) Vampire Weekend Vamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6958</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>They Might Follow You</td>\n",
       "      <td>They Might Follow You Tiny Vipers Tiny Vipers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6958</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "      <td>Monkey Man</td>\n",
       "      <td>Monkey Man You Know I'm No Good Amy Winehouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  song_id  play_count                            title  \\\n",
       "0     6958      447           1               Daisy And Prudence   \n",
       "1     6958      512           1  The Ballad of Michael Valentine   \n",
       "2     6958      549           1        I Stand Corrected (Album)   \n",
       "3     6958      703           1            They Might Follow You   \n",
       "4     6958      719           1                       Monkey Man   \n",
       "\n",
       "                                                text  \n",
       "0       Daisy And Prudence Distillation Erin McKeown  \n",
       "1  The Ballad of Michael Valentine Sawdust The Ki...  \n",
       "2  I Stand Corrected (Album) Vampire Weekend Vamp...  \n",
       "3      They Might Follow You Tiny Vipers Tiny Vipers  \n",
       "4      Monkey Man You Know I'm No Good Amy Winehouse  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# see the first 5 records of the df_small dataset\n",
    "#df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qDcYHwZTR-F5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the series of indices from the data\n",
    "indices = pd.Series(df_small.index)\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9UINF3Nwvwfr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Hank\n",
      "[nltk_data]     Daily\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Hank\n",
      "[nltk_data]     Daily\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Hank\n",
      "[nltk_data]     Daily\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary packages to work with text data\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt2vitlnhoEg"
   },
   "source": [
    "We will create a **function to pre-process the text data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j5QSSeUvR-F6"
   },
   "outputs": [],
   "source": [
    "# Function to tokenize the text\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\",\" \",text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [word for word in tokens if word not in stopwords.words(\"english\")] #Use stopwords of english\n",
    "    text_lems = [WordNetLemmatizer().lemmatize(lem).strip() for lem in words]\n",
    "\n",
    "    return text_lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RI_onIGdR-F6"
   },
   "outputs": [],
   "source": [
    "#Create tfidf vectorizer \n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
    "\n",
    "# Fit_transfrom the above vectorizer on the text column and then convert the output into an array.\n",
    "df_tfidf = tfidf.fit_transform(df_small['text'].values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Beak6ODRR-F7"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 143. GiB for an array with shape (138301, 138301) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_8944/2898730598.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compute the cosine similarity for the tfidf above output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msimilar_songs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msimilar_songs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0m\u001b[0;32m   1189\u001b[0m                         dense_output=dense_output)\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 143. GiB for an array with shape (138301, 138301) and data type float64"
     ]
    }
   ],
   "source": [
    "# Compute the cosine similarity for the tfidf above output\n",
    "similar_songs = cosine_similarity(df_tfidf, df_tfidf)\n",
    "similar_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jjo3UHKhoEh"
   },
   "source": [
    " Finally, let's create a function to find most similar songs to recommend for a given song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "upANOISkR-F8"
   },
   "outputs": [],
   "source": [
    "# function that takes in song title as input and returns the top 10 recommended songs\n",
    "def recommendations(title, similar_songs):\n",
    "    \n",
    "    recommended_songs = []\n",
    "    \n",
    "    # gettin the index of the song that matches the title\n",
    "    idx = indices[indices == title].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(similar_songs[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar songs\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    print(top_10_indexes)\n",
    "    \n",
    "    # populating the list with the titles of the best 10 matching songs\n",
    "    for i in top_10_indexes:\n",
    "        recommended_songs.append(list(df_small.index)[i])\n",
    "        \n",
    "    return recommended_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4EINBmkR-F8"
   },
   "source": [
    "Recommending 10 songs similar to Learn to Fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ohEK5dkVR-F8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similar_songs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HANKDA~1\\AppData\\Local\\Temp/ipykernel_8944/1179045009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make the recommendation for the song with title 'Learn To Fly'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learn To Fly\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilar_songs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'similar_songs' is not defined"
     ]
    }
   ],
   "source": [
    "# Make the recommendation for the song with title 'Learn To Fly'\n",
    "recommendations(\"Learn To Fly\", similar_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ7iI5QJ0oem"
   },
   "source": [
    "**Observations and Insights:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k0w-Ci6vYY4"
   },
   "source": [
    "## **Conclusion and Recommendations:** \n",
    "\n",
    "- **Refined Insights -** What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "- **Comparison of various techniques and their relative performance -** How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "- **Proposal for the final solution design -** What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reference_Notebook_Milestone_2_Recommendation_Systems.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
